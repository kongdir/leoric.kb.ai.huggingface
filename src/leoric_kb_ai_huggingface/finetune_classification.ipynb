{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0ca2cc3-f3eb-4d33-bb5f-f9c32f2a827b",
   "metadata": {},
   "source": [
    "# AI Powered Request Dispatcher - HuggingFace Trainer Edition\n",
    "\n",
    "This notebook demonstrates how to fine-tune a DistilBERT model for text classification using the **HuggingFace `datasets` library** and **`Trainer` API** - the modern, recommended approach for fine-tuning transformers.\n",
    "\n",
    "## Why Use HuggingFace Trainer?\n",
    "\n",
    "- **Less boilerplate**: No manual training loops needed\n",
    "- **Built-in features**: Checkpointing, logging, evaluation, mixed precision\n",
    "- **Best practices**: Gradient accumulation, learning rate scheduling\n",
    "- **Easy experimentation**: Just change `TrainingArguments`\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. Load and preprocess data with HuggingFace `datasets`\n",
    "2. Tokenize datasets efficiently with `.map()`\n",
    "3. Configure training with `TrainingArguments`\n",
    "4. Fine-tune using `Trainer`\n",
    "5. Evaluate with custom metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c3d4e5-f6a7-8901-2345-67890abcdef1",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3d4e5f6-a7b8-9012-3456-7890abcdef12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# 禁用 tokenizers 并行，彻底消除警告: huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "# HuggingFace libraries\n",
    "import evaluate\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding,\n",
    ")\n",
    "\n",
    "import helper_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29ac09c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Check device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa421fa-5cfa-4026-bac7-67448130ea7e",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data\n",
    "\n",
    "We'll use the Databricks Dolly 15k dataset for instruction classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8e66726-5b83-498c-8ac3-aca10597e6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 26238 samples\n",
      "\n",
      "Original categories: ['closed_qa', 'classification', 'open_qa', 'information_extraction', 'brainstorming', 'general_qa', 'summarization', 'creative_writing']\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data_path = \"./databricks-dolly-15k-dataset/databricks-dolly_augmented.csv\"\n",
    "df = pd.read_csv(data_path).dropna().reset_index(drop=True)\n",
    "\n",
    "print(f\"Loaded {len(df)} samples\")\n",
    "print(f\"\\nOriginal categories: {df['category'].unique().tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "453f4f3c-e631-44bd-834c-d3ced971f487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consolidated categories: ['q_and_a', 'classification', 'information_distillation', 'brainstorming', 'creative_writing']\n"
     ]
    }
   ],
   "source": [
    "# Consolidate similar categories for a more focused dispatcher\n",
    "category_map = {\n",
    "    \"general_qa\": \"q_and_a\",\n",
    "    \"open_qa\": \"q_and_a\",\n",
    "    \"closed_qa\": \"q_and_a\",\n",
    "    \"information_extraction\": \"information_distillation\",\n",
    "    \"summarization\": \"information_distillation\"\n",
    "}\n",
    "\n",
    "df['category'] = df['category'].replace(category_map)\n",
    "print(f\"Consolidated categories: {df['category'].unique().tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d6b5653-8184-4036-b15c-0fc18521ce5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label mappings:\n",
      "  0: q_and_a                   (13243 samples)\n",
      "  1: classification            (3918 samples)\n",
      "  2: information_distillation  (4681 samples)\n",
      "  3: brainstorming             (3113 samples)\n",
      "  4: creative_writing          (1283 samples)\n"
     ]
    }
   ],
   "source": [
    "# Create label mappings\n",
    "unique_categories = df['category'].unique().tolist()\n",
    "label2id = {category: i for i, category in enumerate(unique_categories)}\n",
    "id2label = {i: category for category, i in label2id.items()}\n",
    "\n",
    "# Add numeric labels\n",
    "df['label'] = df['category'].map(label2id)\n",
    "\n",
    "print(\"Label mappings:\")\n",
    "for cat, idx in label2id.items():\n",
    "    count = len(df[df['label'] == idx])\n",
    "    print(f\"  {idx}: {cat:<25} ({count} samples)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f72292-5d2f-47d4-bdcd-08597931091a",
   "metadata": {},
   "source": [
    "## 2. Create HuggingFace Dataset\n",
    "\n",
    "Instead of creating a custom PyTorch Dataset, we use HuggingFace's `Dataset` class which integrates perfectly with the `Trainer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af1b02f7-e93a-4627-ab95-0874e0ccb6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 26238\n",
      "})\n",
      "\n",
      "Example: {'text': 'When did Virgin Australia start operating?', 'label': 0}\n"
     ]
    }
   ],
   "source": [
    "# Create HuggingFace Dataset from pandas DataFrame\n",
    "# We only need the 'instruction' (text) and 'label' columns\n",
    "dataset = Dataset.from_pandas(df[['instruction', 'label']])\n",
    "\n",
    "# Rename 'instruction' to 'text' for clarity\n",
    "dataset = dataset.rename_column('instruction', 'text')\n",
    "\n",
    "print(dataset)\n",
    "print(f\"\\nExample: {dataset[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74ceb6f9-7e94-48ce-9ad2-f0dd9ff9bf1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 20990\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 5248\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Split into train/validation (80/20)\n",
    "dataset_split = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "# Rename 'test' to 'validation' for clarity\n",
    "dataset_dict = DatasetDict({\n",
    "    'train': dataset_split['train'],\n",
    "    'validation': dataset_split['test']\n",
    "})\n",
    "\n",
    "print(dataset_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de448f7b-f0e1-43fa-9e89-a3a40d827651",
   "metadata": {},
   "source": [
    "## 3. Load Tokenizer and Model\n",
    "\n",
    "We'll use DistilBERT - fast, efficient, and perfect for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a29e54b-f761-4803-8d35-a1c11a91e835",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded with 5 classification labels\n"
     ]
    }
   ],
   "source": [
    "model_name = \"distilbert-base-uncased\"\n",
    "num_labels = len(unique_categories)\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Load model with classification head\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_labels,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "\n",
    "print(f\"Model loaded with {num_labels} classification labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e72f5a5-7cf1-438e-b63d-90e396cb1f17",
   "metadata": {},
   "source": [
    "## 4. Tokenize Dataset\n",
    "\n",
    "Using `.map()` is the HuggingFace way - efficient, batched, and cacheable!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9d0e1f2-a3b4-5678-9012-def123456789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b43c718f128497ab14c39f51e98558b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20990 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1046d8343eb4a79a9945d4d6a44389c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5248 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['label', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 20990\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['label', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 5248\n",
      "    })\n",
      "})\n",
      "\n",
      "Tokenized example keys: dict_keys(['label', 'input_ids', 'attention_mask'])\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    \"\"\"Tokenize a batch of examples.\"\"\"\n",
    "    return tokenizer(\n",
    "        examples['text'],\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        # Don't pad here - let DataCollator do dynamic padding\n",
    "    )\n",
    "\n",
    "# Apply tokenization to all splits\n",
    "tokenized_datasets = dataset_dict.map(\n",
    "    tokenize_function,\n",
    "    batched=True,  # Process in batches for efficiency\n",
    "    remove_columns=['text'],  # Remove original text column\n",
    ")\n",
    "\n",
    "print(tokenized_datasets)\n",
    "print(f\"\\nTokenized example keys: {tokenized_datasets['train'][0].keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "684f351f-7fef-4e93-a6a8-fcffd97a1692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data collator for dynamic padding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a3b4c5-d6e7-8901-2345-123456789012",
   "metadata": {},
   "source": [
    "## 5. Define Evaluation Metrics\n",
    "\n",
    "The `Trainer` needs a function to compute metrics during evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a000634c-1da4-43b7-8899-18b6c1d50ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load evaluation metrics\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Compute accuracy and F1 score for evaluation.\"\"\"\n",
    "    # predictions.shape: (sample size, n_classes): (5248, 5)\n",
    "    # labels.shape: (sample size, ): (5248, )\n",
    "    predictions, labels_ids = eval_pred\n",
    "    \n",
    "    # 打印类型和形状，帮助调试\n",
    "    # print(f\"预测值类型: {type(predictions)}, 形状: {predictions.shape}\")\n",
    "    # print(f\"真实标签类型: {type(labels_ids)}, 形状: {labels_ids.shape}\")\n",
    "\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels_ids)\n",
    "    f1 = f1_metric.compute(predictions=predictions, references=labels_ids, average='weighted')\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy['accuracy'],\n",
    "        'f1': f1['f1'],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3e008a-6227-4c7e-8531-4bf3819de99d",
   "metadata": {},
   "source": [
    "## 6. Optional: Freeze Layers for Efficient Fine-Tuning\n",
    "\n",
    "Parameter-efficient fine-tuning (PEFT) - train only the last few layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af696ef3-96bb-46b5-9105-23404548d2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 21,858,053 / 66,957,317 (32.6%)\n"
     ]
    }
   ],
   "source": [
    "def freeze_base_layers(model, layers_to_train=3):\n",
    "    \"\"\"\n",
    "    Freeze all but the last N transformer layers and classification head.\n",
    "    \n",
    "    Args:\n",
    "        model: DistilBERT model\n",
    "        layers_to_train: Number of final transformer layers to keep trainable\n",
    "    \"\"\"\n",
    "    # Freeze all parameters first\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # Unfreeze last N transformer layers\n",
    "    transformer_layers = model.distilbert.transformer.layer\n",
    "    for i in range(layers_to_train):\n",
    "        for param in transformer_layers[-(i + 1)].parameters():\n",
    "            param.requires_grad = True\n",
    "    \n",
    "    # Always unfreeze classification head\n",
    "    for param in model.pre_classifier.parameters():\n",
    "        param.requires_grad = True\n",
    "    for param in model.classifier.parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "    # Count trainable parameters\n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    total = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Trainable parameters: {trainable:,} / {total:,} ({100*trainable/total:.1f}%)\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Apply freezing (optional - comment out for full fine-tuning)\n",
    "model = freeze_base_layers(model, layers_to_train=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04855a3a-984e-4d01-8b90-29212f60a988",
   "metadata": {},
   "source": [
    "## 7. Configure Training with TrainingArguments\n",
    "\n",
    "This is where HuggingFace Trainer shines - all hyperparameters in one place!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62d0f298-76ab-4d85-8069-9abf53a374b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training configuration ready!\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./model_results/dispatcher-checkpoints\",\n",
    "    \n",
    "    # Training hyperparameters\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    \n",
    "    # Evaluation strategy\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    \n",
    "    dataloader_num_workers=2\n",
    ")\n",
    "\n",
    "print(\"Training configuration ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90916ae9-bd55-4e47-a2a9-ec8c39d6c176",
   "metadata": {},
   "source": [
    "## 8. Create Trainer and Train!\n",
    "\n",
    "The Trainer handles everything: training loop, evaluation, checkpointing, logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55f81c51-09b0-47ec-9b8b-ae015794d4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/08/14kn6dm126b64wdxdz_dx4pm0000gn/T/ipykernel_78489/4103696212.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer initialized!\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['validation'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(\"Trainer initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "259c8be4-15b0-41a8-b524-01ea310cdfa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/l0k00au/Projects/Leoric/AI/leoric.kb.ai.huggingface/.venv/lib/python3.14/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3280' max='3280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3280/3280 24:11, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.769100</td>\n",
       "      <td>0.453181</td>\n",
       "      <td>0.842226</td>\n",
       "      <td>0.839662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.418400</td>\n",
       "      <td>0.376460</td>\n",
       "      <td>0.875381</td>\n",
       "      <td>0.873578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.310900</td>\n",
       "      <td>0.370492</td>\n",
       "      <td>0.885671</td>\n",
       "      <td>0.884201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.163100</td>\n",
       "      <td>0.401992</td>\n",
       "      <td>0.887005</td>\n",
       "      <td>0.886145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.122600</td>\n",
       "      <td>0.433573</td>\n",
       "      <td>0.891006</td>\n",
       "      <td>0.889733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/l0k00au/Projects/Leoric/AI/leoric.kb.ai.huggingface/.venv/lib/python3.14/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Users/l0k00au/Projects/Leoric/AI/leoric.kb.ai.huggingface/.venv/lib/python3.14/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Users/l0k00au/Projects/Leoric/AI/leoric.kb.ai.huggingface/.venv/lib/python3.14/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Users/l0k00au/Projects/Leoric/AI/leoric.kb.ai.huggingface/.venv/lib/python3.14/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training complete!\n",
      "Total training time: 1461.5 seconds\n"
     ]
    }
   ],
   "source": [
    "# Train the model!\n",
    "print(\"Starting training...\\n\")\n",
    "train_result = trainer.train()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Training complete!\")\n",
    "print(f\"Total training time: {train_result.metrics['train_runtime']:.1f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab458dc-4971-4757-9947-bdd976d48fc4",
   "metadata": {},
   "source": [
    "## 9. Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3202c72e-fdfa-4c24-8f1a-13980a00c94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/l0k00au/Projects/Leoric/AI/leoric.kb.ai.huggingface/.venv/lib/python3.14/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Final Validation Metrics\n",
      "==================================================\n",
      "Loss:     0.4336\n",
      "Accuracy: 0.8910\n",
      "F1 Score: 0.8897\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation on validation set\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Final Validation Metrics\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Loss:     {eval_results['eval_loss']:.4f}\")\n",
    "print(f\"Accuracy: {eval_results['eval_accuracy']:.4f}\")\n",
    "print(f\"F1 Score: {eval_results['eval_f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ceccc50e-2dfe-4e40-b239-5c308c14d137",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/l0k00au/Projects/Leoric/AI/leoric.kb.ai.huggingface/.venv/lib/python3.14/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "                              q_and_a  classifica  informatio  brainstorm  creative_w\n",
      "                  q_and_a        2477           4          78          70          13\n",
      "           classification          10         768           3           3           0\n",
      " information_distillation         191           3         742          11           0\n",
      "            brainstorming         103           2          11         489           3\n",
      "         creative_writing          51           1           1          14         200\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions for confusion matrix\n",
    "predictions = trainer.predict(tokenized_datasets['validation'])\n",
    "pred_labels = np.argmax(predictions.predictions, axis=1)\n",
    "true_labels = predictions.label_ids\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(true_labels, pred_labels)\n",
    "print(\"\\nConfusion Matrix:\\n\")\n",
    "print(f\"{'':>25}\", end='')\n",
    "for i in range(len(id2label)):\n",
    "    print(f\"{id2label[i][:10]:>12}\", end='')\n",
    "print()\n",
    "for i, row in enumerate(cm):\n",
    "    print(f\"{id2label[i]:>25}\", end='')\n",
    "    for val in row:\n",
    "        print(f\"{val:>12}\", end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dc2fef-1491-42a6-b742-4ef37e9ef71b",
   "metadata": {},
   "source": [
    "## 10. Test on New Instructions\n",
    "\n",
    "Let's test our dispatcher on some unseen instructions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e738f56-3172-4b61-85c0-179f5a37bcbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on new instructions:\n",
      "\n",
      "  [         q_and_a         ] What is the capital of France?\n",
      "  [    creative_writing     ] Write a short poem about coding\n",
      "  [     classification      ] Is a tomato a fruit or vegetable?\n",
      "  [information_distillation ] Summarize the main points of this article\n",
      "  [      brainstorming      ] Give me 5 ideas for a birthday party\n"
     ]
    }
   ],
   "source": [
    "def predict_category(text: str) -> str:\n",
    "    \"\"\"Predict the category for a given instruction.\"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        predicted_class = torch.argmax(outputs.logits, dim=1).item()\n",
    "    \n",
    "    return id2label[predicted_class]\n",
    "\n",
    "# Test examples\n",
    "test_instructions = [\n",
    "    \"What is the capital of France?\",\n",
    "    \"Write a short poem about coding\",\n",
    "    \"Is a tomato a fruit or vegetable?\",\n",
    "    \"Summarize the main points of this article\",\n",
    "    \"Give me 5 ideas for a birthday party\",\n",
    "]\n",
    "\n",
    "print(\"Predictions on new instructions:\\n\")\n",
    "for instruction in test_instructions:\n",
    "    category = predict_category(instruction)\n",
    "    print(f\"  [{category:^25}] {instruction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aada1cd-91c9-4176-a360-be65609fe5ca",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### What We Did\n",
    "\n",
    "1. **Loaded data** into HuggingFace `Dataset` (no custom PyTorch Dataset needed!)\n",
    "2. **Tokenized efficiently** using `.map()` with batching\n",
    "3. **Configured training** with `TrainingArguments` (all hyperparameters in one place)\n",
    "4. **Fine-tuned** using `Trainer` (no manual training loop!)\n",
    "5. **Evaluated** with built-in metrics computation\n",
    "\n",
    "### Benefits of This Approach\n",
    "\n",
    "- **~50% less code** compared to manual training loops\n",
    "- **Automatic checkpointing** and best model selection\n",
    "- **Built-in logging** (TensorBoard, W&B support)\n",
    "- **Easy to experiment** with hyperparameters\n",
    "- **Production-ready** with proper evaluation\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Try different models (`bert-base-uncased`, `roberta-base`)\n",
    "- Experiment with learning rate schedules\n",
    "- Add class weights for imbalanced data\n",
    "- Use `push_to_hub()` to share on HuggingFace Hub"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leoric-kb-ai-huggingface (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
